{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Input\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 5000\n",
    "batch_size = 128\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "categories = ['alt.atheism', 'talk.religion.misc','comp.graphics', 'sci.space']\n",
    "#categories = None\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "from pprint import pprint\n",
    "pprint(list(newsgroups_train.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting text to vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (2034, 5000)\n",
      "x_test shape: (1353, 5000)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(newsgroups_train[\"data\"])\n",
    "x_train = tokenizer.texts_to_matrix(newsgroups_train[\"data\"], mode='binary')\n",
    "x_test = tokenizer.texts_to_matrix(newsgroups_test[\"data\"], mode='binary')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(newsgroups_train[\"target\"]) + 1\n",
    "print(num_classes, 'classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert class vector to binary class matrix (for use with categorical_crossentropy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (2034, 4)\n",
      "y_test shape: (1353, 4)\n"
     ]
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(newsgroups_train[\"target\"], num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(newsgroups_test[\"target\"], num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building model functionally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "a = Input(shape=(max_words,))\n",
    "b = Dense(512)(a)\n",
    "b = Activation('relu')(b)\n",
    "b = Dropout(0.5)(b)\n",
    "b = Dense(num_classes)(b)\n",
    "b = Activation('softmax')(b)\n",
    "model = Model(inputs=a, outputs=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x27b415d3a58>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x27b415d38d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x27b41596da0>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x27b415e9f98>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x27b40b5bf98>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x27b415d41d0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend: tensorflow\n",
      "class_name: Model\n",
      "config:\n",
      "  input_layers:\n",
      "  - [input_1, 0, 0]\n",
      "  layers:\n",
      "  - class_name: InputLayer\n",
      "    config:\n",
      "      batch_input_shape: !!python/tuple [null, 5000]\n",
      "      dtype: float32\n",
      "      name: input_1\n",
      "      sparse: false\n",
      "    inbound_nodes: []\n",
      "    name: input_1\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: linear\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense\n",
      "      trainable: true\n",
      "      units: 512\n",
      "      use_bias: true\n",
      "    inbound_nodes:\n",
      "    - - - input_1\n",
      "        - 0\n",
      "        - 0\n",
      "        - {}\n",
      "    name: dense\n",
      "  - class_name: Activation\n",
      "    config: {activation: relu, dtype: float32, name: activation, trainable: true}\n",
      "    inbound_nodes:\n",
      "    - - - dense\n",
      "        - 0\n",
      "        - 0\n",
      "        - {}\n",
      "    name: activation\n",
      "  - class_name: Dropout\n",
      "    config: {dtype: float32, name: dropout, noise_shape: null, rate: 0.5, seed: null,\n",
      "      trainable: true}\n",
      "    inbound_nodes:\n",
      "    - - - activation\n",
      "        - 0\n",
      "        - 0\n",
      "        - {}\n",
      "    name: dropout\n",
      "  - class_name: Dense\n",
      "    config:\n",
      "      activation: linear\n",
      "      activity_regularizer: null\n",
      "      bias_constraint: null\n",
      "      bias_initializer:\n",
      "        class_name: Zeros\n",
      "        config: {dtype: float32}\n",
      "      bias_regularizer: null\n",
      "      dtype: float32\n",
      "      kernel_constraint: null\n",
      "      kernel_initializer:\n",
      "        class_name: GlorotUniform\n",
      "        config: {dtype: float32, seed: null}\n",
      "      kernel_regularizer: null\n",
      "      name: dense_1\n",
      "      trainable: true\n",
      "      units: 4\n",
      "      use_bias: true\n",
      "    inbound_nodes:\n",
      "    - - - dropout\n",
      "        - 0\n",
      "        - 0\n",
      "        - {}\n",
      "    name: dense_1\n",
      "  - class_name: Activation\n",
      "    config: {activation: softmax, dtype: float32, name: activation_1, trainable: true}\n",
      "    inbound_nodes:\n",
      "    - - - dense_1\n",
      "        - 0\n",
      "        - 0\n",
      "        - {}\n",
      "    name: activation_1\n",
      "  name: model\n",
      "  output_layers:\n",
      "  - [activation_1, 0, 0]\n",
      "keras_version: 2.2.4-tf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.to_yaml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\asergeev\\AppData\\Local\\Temp\\tmp0ngdnn4_\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\asergeev\\\\AppData\\\\Local\\\\Temp\\\\tmp0ngdnn4_', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000027B418AAAC8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.keras.estimator.model_to_estimator(keras_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='C:\\\\Users\\\\asergeev\\\\AppData\\\\Local\\\\Temp\\\\tmp0ngdnn4_\\\\keras\\\\keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('C:\\\\Users\\\\asergeev\\\\AppData\\\\Local\\\\Temp\\\\tmp0ngdnn4_\\\\keras\\\\keras_model.ckpt',)\n",
      "INFO:tensorflow:Warm-starting variable: dense/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/iterations; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/lr; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/beta_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: Adam/decay; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_1; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_2; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_3; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_4; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_5; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_6; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_7; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_8; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_9; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_10; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: training/Adam/Variable_11; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\asergeev\\AppData\\Local\\Temp\\tmp0ngdnn4_\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4382433, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 81 into C:\\Users\\asergeev\\AppData\\Local\\Temp\\tmp0ngdnn4_\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.013794657.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0x27b418bdcf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=epochs,\n",
    "    shuffle=False)\n",
    "estimator.train(input_fn=train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:363: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-07T11:13:05Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\asergeev\\AppData\\Local\\Temp\\tmp0ngdnn4_\\model.ckpt-81\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-07-11:13:06\n",
      "INFO:tensorflow:Saving dict for global step 81: categorical_accuracy = 0.89135253, global_step = 81, loss = 0.35404265\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 81: C:\\Users\\asergeev\\AppData\\Local\\Temp\\tmp0ngdnn4_\\model.ckpt-81\n",
      "\n",
      "\n",
      "Score: {'categorical_accuracy': 0.89135253, 'loss': 0.35404265, 'global_step': 81}\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=x_test,\n",
    "    y=y_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "score = estimator.evaluate(input_fn=test_input_fn)\n",
    "print('\\n')\n",
    "print('Score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: D:/PythonProjects/Machine-Learning-Distributed-Systems/tmp/news/1\\saved_model.pb\n",
      "\n",
      "Saved model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Keras session and save the model\n",
    "# The signature definition is defined by the input and output tensors,\n",
    "# and stored with the default serving key\n",
    "import os\n",
    "#import tempfile\n",
    "#MODEL_DIR = tempfile.gettempdir()\n",
    "#version = 1\n",
    "export_path = 'D:/PythonProjects/Machine-Learning-Distributed-Systems/tmp/news/1'\n",
    "#print('export_path = {}\\n'.format(export_path))\n",
    "if os.path.isdir(export_path):\n",
    "    print('\\nAlready saved a model, cleaning up\\n')\n",
    "    !rm -r {export_path}\n",
    "\n",
    "#tf.contrib.saved_model.save_keras_model(model, '/tmp/news')\n",
    "tf.saved_model.simple_save(\n",
    "    tf.keras.backend.get_session(),\n",
    "    export_path,\n",
    "    inputs={'document': model.input},\n",
    "    outputs={t.name:t for t in model.outputs})\n",
    "\n",
    "#export_path='D:/PythonProjects/Machine-Learning-Distributed-Systems/tmp/news/1'\n",
    "#print('\\nSaved model:')\n",
    "#!ls -l {export_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['document'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5000)\n",
      "        name: input_1:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['activation_1/Softmax:0'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 4)\n",
      "        name: activation_1/Softmax:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"MODEL_DIR\"] = MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash --bg \n",
    "#nohup tensorflow_model_server \\\n",
    "#  --rest_api_port=8501 \\\n",
    "#  --model_name=news \\\n",
    "#  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tail server.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\"signature_name\": \"serving_default\", \"instances\": ...  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x_test[0:3].tolist()})\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.268494, 0.277034, 0.21562, 0.238852],\n",
       " [0.24658, 0.250593, 0.254366, 0.248461],\n",
       " [0.261858, 0.334612, 0.194442, 0.209088]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "json_response = requests.post('http://localhost:8501/v1/models/news:predict', data=data, headers=headers)\n",
    "predictions = json.loads(json_response.text)['predictions']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: 1, real: 2\n",
      "predicted: 2, real: 1\n",
      "predicted: 1, real: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "  print(\"predicted: {}, real: {}\".format(np.argmax(predictions[i]), newsgroups_test[\"target\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# import os\n",
    "# export_path_base = '/home/asergeev/Desktop/news'\n",
    "# export_version = 1\n",
    "\n",
    "# export_path = os.path.join(\n",
    "#   tf.compat.as_bytes(export_path_base),\n",
    "#   tf.compat.as_bytes(str(export_version)))\n",
    "# print('Exporting trained model to', export_path)\n",
    "# builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "# # создаем входы и выходы из тензоров\n",
    "# model_input = tf.saved_model.utils.build_tensor_info(model.input)\n",
    "# model_output = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "\n",
    "# # создаем сигнатуру для предсказания, в которой устанавливаем входы и выходы модели\n",
    "# prediction_signature = (\n",
    "#   tf.saved_model.signature_def_utils.build_signature_def(\n",
    "#       inputs={'words': model_input},\n",
    "#       outputs={'scores': model_output},\n",
    "#       method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "# # добавляем сигнатуры к SavedModelBuilder\n",
    "# legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "# builder.add_meta_graph_and_variables(\n",
    "#   sess, [tf.saved_model.tag_constants.SERVING],\n",
    "#   signature_def_map={\n",
    "#       'predict':\n",
    "#           prediction_signature,\n",
    "#   },\n",
    "#   legacy_init_op=legacy_init_op)\n",
    "\n",
    "# builder.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
